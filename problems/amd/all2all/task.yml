# name: single node all2all

files:
  - {"name": "submission.py", "source": "@SUBMISSION@"}
  - {"name": "task.py", "source": "task.py"}
  - {"name": "utils.py", "source": "../utils.py"}
  - {"name": "reference.py", "source": "reference.py"}
  - {"name": "eval.py", "source": "../eval.py"}

lang: "py"

description: |
  
  You will implement a custom single node all2all kernel optimized for MI300.
  You will be given 
  To be explicit, you will be given a tuple of tensors:
  ```
  (a, b, a_scale, b_scale, c)
  ```
  where `a` and `b` are the input matrices, `a_scale` and `b_scale` are the scaling factors for `a` and `b` respectively,
  and `c` is the output matrix:
  * `a` is M x K in column-major order in e4m3fnuz
  * `b` is N x K in column-major order in e4m3fnuz
  * `a_scale` is M x K // 128 in column-major order in fp32
  * `b_scale` is N // 128 x K // 128 in column-major order in fp32
  * `c` is M x N in ROW-major order in bf16
  
  Matrix sizes `m` and `n` are divisible by 64, `k` is divisible by 128.

  The ranking criteria is the geometric mean of the benchmark results.

  For the grand price, your kernel will be evaluated against the speed of light analysis
  and the solution closest to the speed of light will be awarded the grand price.
  ```
  The speed of light analysis is:
   M       N       K     time[us]

  ```


tests:
  - {"num_experts": 16, "experts_per_token": 4, "hidden_dim": 4096, "max_num_tokens": 256, "seed": 6635}
  - {"num_experts": 24, "experts_per_token": 8, "hidden_dim": 7168, "max_num_tokens": 256, "seed": 6635}
  - {"num_experts": 32, "experts_per_token": 8, "hidden_dim": 4096, "max_num_tokens": 256, "seed": 6635}
  - {"num_experts": 48, "experts_per_token": 8, "hidden_dim": 7168, "max_num_tokens": 128, "seed": 6635}
  - {"num_experts": 64, "experts_per_token": 8, "hidden_dim": 4096, "max_num_tokens": 128, "seed": 6635}
  - {"num_experts": 80, "experts_per_token": 8, "hidden_dim": 7168, "max_num_tokens": 128, "seed": 6635}
  - {"num_experts": 96, "experts_per_token": 8, "hidden_dim": 4096, "max_num_tokens": 128, "seed": 6635}
  - {"num_experts": 128, "experts_per_token": 8, "hidden_dim": 7168, "max_num_tokens": 128, "seed": 6635}
  - {"num_experts": 192, "experts_per_token": 8, "hidden_dim": 4096, "max_num_tokens": 128, "seed": 6635}
  - {"num_experts": 256, "experts_per_token": 8, "hidden_dim": 7168, "max_num_tokens": 128, "seed": 6635}


benchmarks:
  - {"num_experts": 32, "experts_per_token": 8, "hidden_dim": 4096, "max_num_tokens": 256, "seed": 6635}
  - {"num_experts": 96, "experts_per_token": 8, "hidden_dim": 7168, "max_num_tokens": 256, "seed": 6635}
  - {"num_experts": 128, "experts_per_token": 8, "hidden_dim": 8192, "max_num_tokens": 256, "seed": 6635}
  - {"num_experts": 192, "experts_per_token": 8, "hidden_dim": 4096, "max_num_tokens": 128, "seed": 6635}
  - {"num_experts": 256, "experts_per_token": 8, "hidden_dim": 7168, "max_num_tokens": 128, "seed": 6635}


ranking_by: "geom"
